=================================
-- 0. 리눅스 기본 명령어 
bash        -> 사용 shell 변경
cd          -> 디렉토리 이동
pwd         -> 현재 위치 확인
whoami      -> 자기 자신확인  
echo        -> 문자열 반환
hostname -i -> 컴퓨터이름, ip 주소 확인
ifconfig    -> ip 주소 확인
ping        -> 목적지 서버통신 확인
ls -lF      -> 파일의 목록 확인
mkdir       -> 디렉토리 만들기
rm -r       -> 하위 디렉토리 파일 지우기
clear       -> 화면지우기
cat         -> 파일의 내용확인

-- editer 설치
apt-get install nano
nano

netstat -tnlp
	-t : 모든 TCP 연결을 표시
	-n : 서비스 명 대신 포트 번호를 표시
	-l : 수신 소켓을 표시
	-p : 포트에서 수신하는 어플리케이션/데몬의 이름을 표시


=================================
-- 1. docker 및 ubuntu 가상서버 구축
-- 1.1 하둡용 우분투 설치

--  도커 설치후 cmd창에 입력
docker pull shinho/hadoop3.4.0

-- 이미지 생성하기..
docker commit master shinho/hadoop3.4.0

-------
-- 1.2 Docker hadoop Image로 각 노드생성 
-- 마스터 노드 하나, worker 노드 네 개 생성

$ docker run -it -h master   --name master   -p 5220:22 -p 9870:9870 -p 9864:9864  shinho/hadoop3.4.0

$ docker run -it -h worker01 --name worker01 -p 5221:22 -p 9864:9864 --link master:master shinho/hadoop3.4.0
$ docker run -it -h worker02 --name worker02 -p 5222:22 -p 9864:9864 --link master:master shinho/hadoop3.4.0
$ docker run -it -h worker03 --name worker03 -p 5223:22 -p 9864:9864 --link master:master shinho/hadoop3.4.0

-------
-- 1.3 master, worker IP주소 확인

-- 윈도우 호스트 운영체제라면
-- cmd에서
docker inspect master   | findstr "IPAddress"
docker inspect worker01 | findstr "IPAddress"
docker inspect worker02 | findstr "IPAddress"
docker inspect worker03 | findstr "IPAddress"

-------
-- 1.4 master 에서 /etc/hosts 파일 수정
host : localhost  
port : 5220
save : doc-master
계정 : hadoop / hadoop

$ nano /etc/hosts 마지막 부분에 추가 하기

172.17.0.2 master
172.17.0.3 worker01
172.17.0.4 worker02
172.17.0.5 worker03

-------
-- 1.5 puty로 master에 접속 확인
-- putty 
host,IP : localhost 5220 접속
saved : dk-master

-- 접속계정
hadoop/hadoop

## master에서 worker 노드 접속확인

$ ssh worker01
$ exit
$ ssh worker02
$ exit
$ ssh worker03
$ exit


=================================
-- 5. 하둡 구동 및 확인
-------
-- 5.1 하둡 초기화 및 구동

-- 하둡 초기화
$ cd 
$ hadoop_init

-- 하둡 구동
$ cd
$ start-all.sh

-- 하둡 종료
$ cd
$ stop-all.sh

-------
-- 5.3 정상 작동 확인
root@master:~# jps
1123 ResourceManager
581 DataNode
839 SecondaryNameNode
1355 NodeManager
1806 Jps
351 NameNode

-------
-- 하둡명령어

hdfs dfs -ls /
hdfs dfs -mkdir /aysdata

hdfs dfs -rm /aysdata/Sample.txt 
hdfs dfs –rm -r /aysdata

hdfs dfs -cp /aysdata/Sample.txt /aysdata/Sample2.txt

hdfs dfs -cat /wcnt/part-r-00000
hdfs dfs -get /wcnt/part-r-00000


=================================
-- 6. hadoop를 이용한 wordcount 실습

-- 6.0 fileZilla 구동
-- Host : sftp://loclahost
-- 계정  : hadoop / hadoop
-- port : 5220

-- 6.1 wordcount 프로그램 및 분석용 데이터 Upload

wordcount 프로그램 : mapreduce-0.0.1-SNAPSHOT.jar
wordcount 분석용data : 
   alice.txt, frankenstein.txt,holmes.txt
   대통령 신년사(127건)

-- 6.2 master에서 하둡으로 분석용 data Upload
--  하둡에 분석할 데이터 uplode할 디렉토리 생성
-- master
mkdir tmp_data
mkdir newYear

-- hadoop
hdfs dfs –mkdir /aysdata
hdfs dfs –mkdir /president
hdfs dfs -put ./tmp_data /* /aysdata/
hdfs dfs –put ./newYear/* /president/


-- 분석할 데이터 하둡에Upload. 
-- 6.3 wordcount 명령어 실행
yarn jar mapreduce-0.0.1-SNAPSHOT.jar bigdata.mapreduce.WordCount /aysdata/*.txt /wcnt

-. 명령어설명
	1.yarn jar : 하둡에서 jar파일 실행 명령 
	2.mapreduce-0.0.1-SNAPSHOT.jar  : WordCount 프로그램 패키지
	3.bigdata.mapreduce.WordCount : 실행할 클래스 파일
	4./aysdata/*.txt : 하둡의 분석할 데이터 저장위치
	5./wcnt : 분석결과를 보관할 위치

-- 6.4 wordcount 결과 확인
   hdfs dfs -cat /wcnt/part-r-00000

-. 하둡에서 master로 가져오기 
  hdfs dfs -get /wcnt/part-r-00000

-. 내 컴퓨터로 가져오기
  part-r-00000


--------------------------------
-- 7. Hortonworks Data Platform(HDP) sandbox-3.0.1 
--    설치 실습
-------
-- 7.1 HDP 설치 전 작업
-- git 설치
-- Windows PowerShell 또는
-- git shell 를 관리자 권한으로 창을 열어서 실행
   winget install --id Git.Git -e --source winget
  
-- git wget를 아래 폴더에 복사
C:\Program Files\Git\mingw64\bin


-------
-- 7.2 HDP 설치 파일 다운로드
-- git shell 또는 Windows PowerShell에서 실행
wget https://archive.cloudera.com/hwx-sandbox/hdp/hdp-3.0.1/HDP_3.0.1_docker-deploy-scripts_18120587fc7fb.zip

unzip HDP_3.0.1_deploy-scripts_18120587fc7fb.zip

mkdir sandbox

cd sandbox-hdp 

unzip ../HDP_3.0.1_deploy-scripts_18120587fc7fb.zip

docker-deploy-hdp30.sh


-------
-- 7.3 HDP 컨테이너 쉘 접속: 아래 암바리 암호설정 위한 접속
winpty docker exec -it sandbox-hdp bash
 
-- Ambari admin 비밀번호 초기화
$ /sbin/ambari-admin-password-reset

admin / admin

-- 서버 구동 확인
$ service ambari-server [start | stop | status ]


-------
-- 7.4 HDP 암바리 실행 및 확인

docker container [start | stop | status ] sandbox-hdp
docker container [start | stop | status ] sandbox-proxy

docker container ps

-- Browser에서 접속
localhost:8080
admin / admin